{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                      Ativa\nData                       \n2019-03-31 00:00:00  558.72\n2019-03-31 01:00:00  559.44\n2019-03-31 02:00:00  556.56\n2019-03-31 03:00:00  563.76\n2019-03-31 04:00:00  563.76\n...                     ...\n2019-11-16 20:00:00  614.88\n2019-11-16 21:00:00  615.60\n2019-11-16 22:00:00  609.12\n2019-11-16 23:00:00  612.00\n2019-11-17 00:00:00  613.44\n\n[5545 rows x 1 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Ativa</th>\n    </tr>\n    <tr>\n      <th>Data</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2019-03-31 00:00:00</th>\n      <td>558.72</td>\n    </tr>\n    <tr>\n      <th>2019-03-31 01:00:00</th>\n      <td>559.44</td>\n    </tr>\n    <tr>\n      <th>2019-03-31 02:00:00</th>\n      <td>556.56</td>\n    </tr>\n    <tr>\n      <th>2019-03-31 03:00:00</th>\n      <td>563.76</td>\n    </tr>\n    <tr>\n      <th>2019-03-31 04:00:00</th>\n      <td>563.76</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2019-11-16 20:00:00</th>\n      <td>614.88</td>\n    </tr>\n    <tr>\n      <th>2019-11-16 21:00:00</th>\n      <td>615.60</td>\n    </tr>\n    <tr>\n      <th>2019-11-16 22:00:00</th>\n      <td>609.12</td>\n    </tr>\n    <tr>\n      <th>2019-11-16 23:00:00</th>\n      <td>612.00</td>\n    </tr>\n    <tr>\n      <th>2019-11-17 00:00:00</th>\n      <td>613.44</td>\n    </tr>\n  </tbody>\n</table>\n<p>5545 rows × 1 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 377
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"MeMas_5min.csv\",header=0,infer_datetime_format=True,parse_dates=['Data'],index_col=['Data'])\n",
    "df = df.resample('H').sum().truncate('2019-03-31','2019-11-17')\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "             Ativa\ncount  5545.000000\nmean    887.991906\nstd     356.346149\nmin     125.280000\n25%     613.440000\n50%     696.960000\n75%    1171.440000\nmax    2019.600000",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Ativa</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>5545.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>887.991906</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>356.346149</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>125.280000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>613.440000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>696.960000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>1171.440000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>2019.600000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 378
    }
   ],
   "source": [
    "data_start_date = df.index[0]\n",
    "data_end_date = df.index[-1]\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Para que o modelo seja treinado da maneira correta é preciso separar o conjunto de dados acima em duas partes, de treinamento e validação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "\n",
    "pred_steps = 14\n",
    "pred_length=timedelta(pred_steps)\n",
    "\n",
    "first_day = pd.to_datetime(data_start_date) \n",
    "last_day = pd.to_datetime(data_end_date)\n",
    "\n",
    "val_pred_start = last_day - pred_length\n",
    "val_pred_end = last_day\n",
    "\n",
    "train_pred_start = val_pred_start - pred_length\n",
    "train_pred_end = val_pred_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_length = train_pred_start - first_day\n",
    "\n",
    "train_enc_start = first_day\n",
    "train_enc_end = train_enc_start + enc_length\n",
    "\n",
    "val_enc_start = train_enc_start + pred_length\n",
    "val_enc_end = val_enc_start + enc_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Train encoding: 2019-03-31 00:00:00 - 2019-10-20 00:00:00\nTrain prediction: 2019-10-20 00:00:00 - 2019-11-03 00:00:00 \n\nVal encoding: 2019-04-14 00:00:00 - 2019-11-03 00:00:00\nVal prediction: 2019-11-03 00:00:00 - 2019-11-17 00:00:00\n\nEncoding interval: 203\nPrediction interval: 14\n"
    }
   ],
   "source": [
    "print('Train encoding:', train_enc_start, '-', train_enc_end)\n",
    "print('Train prediction:', train_pred_start, '-', train_pred_end, '\\n')\n",
    "print('Val encoding:', val_enc_start, '-', val_enc_end)\n",
    "print('Val prediction:', val_pred_start, '-', val_pred_end)\n",
    "\n",
    "print('\\nEncoding interval:', enc_length.days)\n",
    "print('Prediction interval:', pred_length.days)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### É importante deixar os dados sempre nos mesmos dias da semana, para que a sazonalidade semanal esteja bem definida na nossa aplicação específica (consumo de energia elétrica). Nesse caso todas as datas estão no domingo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_to_index = pd.Series(index=df.index,data=np.arange(len(df)))\n",
    "series_array = pd.Series(df['Ativa'].values)\n",
    "\n",
    "\n",
    "def get_time_block_series(series_array, date_to_index, start_date, end_date):\n",
    "    \n",
    "    inds = date_to_index[start_date.to_datetime64():end_date.to_datetime64()]\n",
    "    return series_array[inds]\n",
    "\n",
    "\n",
    "def transform_series_encode(series_array):\n",
    "    series_array = np.log1p(np.nan_to_num(series_array)) # filling NaN with 0\n",
    "    series_mean = series_array.mean(axis=0) \n",
    "    series_array = series_array - series_mean\n",
    "    series_array = series_array.reshape(len(series_array),1)\n",
    "    series_array = series_array.reshape((series_array.shape[0],series_array.shape[1], 1))\n",
    "    \n",
    "    return series_array, series_mean\n",
    "\n",
    "\n",
    "def transform_series_decode(series_array, encode_series_mean):\n",
    "    \n",
    "    series_array = np.log1p(np.nan_to_num(series_array)) # filling NaN with 0\n",
    "    series_array = series_array - encode_series_mean\n",
    "    series_array = series_array.reshape(len(series_array),1)\n",
    "    series_array = series_array.reshape((series_array.shape[0],series_array.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "latent_dim = 50 # LSTM hidden units\n",
    "dropout = .20 \n",
    "\n",
    "# Define an input series and encode it with an LSTM. \n",
    "encoder_inputs = Input(shape=(None, 1)) \n",
    "encoder = LSTM(latent_dim, dropout=dropout, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "\n",
    "# We discard `encoder_outputs` and only keep the final states. These represent the \"context\"\n",
    "# vector that we use as the basis for decoding.\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# Set up the decoder, using `encoder_states` as initial state.\n",
    "# This is where teacher forcing inputs are fed in.\n",
    "decoder_inputs = Input(shape=(None, 1)) \n",
    "\n",
    "# We set up our decoder using `encoder_states` as initial state.  \n",
    "# We return full output sequences and return internal states as well. \n",
    "# We don't use the return states in the training model, but we will use them in inference.\n",
    "decoder_lstm = LSTM(latent_dim, dropout=dropout, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs,\n",
    "                                     initial_state=encoder_states)\n",
    "\n",
    "decoder_dense = Dense(1) # 1 continuous output at each timestep\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# Define the model that will turn\n",
    "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"model_37\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_73 (InputLayer)           (None, None, 1)      0                                            \n__________________________________________________________________________________________________\ninput_74 (InputLayer)           (None, None, 1)      0                                            \n__________________________________________________________________________________________________\nlstm_73 (LSTM)                  [(None, 50), (None,  10400       input_73[0][0]                   \n__________________________________________________________________________________________________\nlstm_74 (LSTM)                  [(None, None, 50), ( 10400       input_74[0][0]                   \n                                                                 lstm_73[0][1]                    \n                                                                 lstm_73[0][2]                    \n__________________________________________________________________________________________________\ndense_37 (Dense)                (None, None, 1)      51          lstm_74[0][0]                    \n==================================================================================================\nTotal params: 20,851\nTrainable params: 20,851\nNon-trainable params: 0\n__________________________________________________________________________________________________\n"
    }
   ],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-462-28f1a4bf5f11>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;31m# lagged target series for teacher forcing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mdecoder_input_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdecoder_target_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[0mdecoder_input_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdecoder_target_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mdecoder_input_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mencoder_input_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "first_n_samples = 20000\n",
    "batch_size = 2**11\n",
    "epochs = 100\n",
    "\n",
    "# sample of series from train_enc_start to train_enc_end  \n",
    "encoder_input_data = get_time_block_series(series_array, date_to_index,train_enc_start, train_enc_end)[:first_n_samples]\n",
    "encoder_input_data, encode_series_mean = transform_series_encode(encoder_input_data)\n",
    "\n",
    "# sample of series from train_pred_start to train_pred_end \n",
    "decoder_target_data = get_time_block_series(series_array, date_to_index, \n",
    "                                            train_pred_start, train_pred_end)[:first_n_samples]\n",
    "decoder_target_data = transform_series_decode(decoder_target_data, encode_series_mean)\n",
    "\n",
    "# lagged target series for teacher forcing\n",
    "decoder_input_data = np.zeros(decoder_target_data.shape)\n",
    "decoder_input_data[:,1:,0] = decoder_target_data[:,:-1,0]\n",
    "decoder_input_data[:,0,0] = encoder_input_data[:,-1,0]\n",
    "\n",
    "model.compile(Adam(), loss='mean_absolute_error')\n",
    "history = model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
    "                     batch_size=batch_size,\n",
    "                     epochs=epochs,\n",
    "                     validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37764bitdad157b643b7445ca0af50d1c9882389",
   "display_name": "Python 3.7.7 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}